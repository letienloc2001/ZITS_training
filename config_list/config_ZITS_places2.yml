SEED: 3407            # random seed
No_Bar: False        # Turn off the progressive bar

use_MPE: True
rel_pos_num: 128
str_size: 256
min_sigma: 3.0
max_sigma: 3.75
round: 64
rezero_for_mpe: True
fix_256: True

transformer_ckpt_path: '/content/drive/Shareddrives/HCMUT/Thesis/checkpoint/ZITS/best_transformer_places2.pth'
gen_weights_path0: '/content/drive/Shareddrives/HCMUT/Thesis/checkpoint/ZITS/ckpt/lama_places2/InpaintingModel_best_gen.pth'   # Not required at the time of eval
dis_weights_path0: '/content/drive/Shareddrives/HCMUT/Thesis/checkpoint/ZITS/ckpt/lama_places2/InpaintingModel_best_dis.pth'   # Not required at the time of eval
structure_upsample_path: '/content/drive/Shareddrives/HCMUT/Thesis/checkpoint/ZITS/ckpt/StructureUpsampling.pth'
###########################
# modify the line path
train_line_path: "/content/drive/Shareddrives/HCMUT/Thesis/data/places265/schoolhouse/target/train-line"
eval_line_path: "/content/drive/Shareddrives/HCMUT/Thesis/data/places265/schoolhouse/target/val-line"
# modify the image path
TRAIN_FLIST: /content/drive/Shareddrives/HCMUT/Thesis/data/places265/schoolhouse/target/train.txt
VAL_FLIST: /content/drive/Shareddrives/HCMUT/Thesis/data/places265/schoolhouse/target/val.txt
TEST_FLIST: /content/drive/Shareddrives/HCMUT/Thesis/data/places265/schoolhouse/target/test.txt
# set the GT images folder for metrics computation
GT_Val_FOLDER: "/content/drive/Shareddrives/HCMUT/Thesis/data/places265/schoolhouse/target/val"
# modify the mask path
TRAIN_MASK_FLIST: [ "/content/drive/Shareddrives/HCMUT/Thesis/data/places265/schoolhouse/mask/train.txt",
                    "/content/drive/Shareddrives/HCMUT/Thesis/data/places265/schoolhouse/mask/train.txt" ]
MASK_RATE: [0.4, 0.8, 1.0]
TEST_MASK_FLIST: "/content/drive/Shareddrives/HCMUT/Thesis/data/places265/schoolhouse/mask/val"


BATCH_SIZE: 16                # input batch size for training
INPUT_SIZE: 256               # input image size for training 0 for original size
START_ITERS: 30000             # start iters for lama
MIX_ITERS: 33000                # gradually mix the edge and line with prediction from transformer
Turning_Point: 38000            # only use the predict from transformer for edge and line
MAX_ITERS: 40000                # maximum number of iterations to train the model

SAVE_INTERVAL: 250           # how many iterations to wait before saving model (0: never)
SAMPLE_INTERVAL:  250        # how many iterations to wait before sampling (0: never)
SAMPLE_SIZE: 12               # number of images to sample
EVAL_INTERVAL: 250            # how many iterations to wait before model evaluation (0: never)
LOG_INTERVAL: 250            # how many iterations to wait before logging training status (0: never)

run_title: 'zits'

training_model:
  kind: default
losses:
  l1:
    weight_missing: 0
    weight_known: 10
  perceptual:
    weight: 0
  adversarial:
    weight: 10
    gp_coef: 0.001
    mask_as_fake_target: true
    allow_scale_mask: true
  feature_matching:
    weight: 100
  resnet_pl:
    weight: 30
    weights_path: './'   # path to ade20k pretrained perceptual loss model provided by LaMa
optimizers:
  warmup_steps: 2000
  generator:
    kind: adam
    lr: 3.0e-4
  discriminator:
    kind: adam
    lr: 1.0e-4
  decay_steps: 400000
  decay_rate: 0.5

generator:
  input_nc: 4
  output_nc: 3
  ngf: 64
  n_downsampling: 3
  n_blocks: 9
  add_out_act: sigmoid
  init_conv_kwargs:
    ratio_gin: 0
    ratio_gout: 0
    enable_lfu: false
  downsample_conv_kwargs:
    ratio_gin: 0
    ratio_gout: 0
    enable_lfu: false
  resnet_conv_kwargs:
    ratio_gin: 0.75
    ratio_gout: 0.75
    enable_lfu: false
discriminator:
  input_nc: 3
